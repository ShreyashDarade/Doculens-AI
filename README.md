<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge&logo=python" alt="Python">
  <img src="https://img.shields.io/badge/FastAPI-0.104+-green?style=for-the-badge&logo=fastapi" alt="FastAPI">
  <img src="https://img.shields.io/badge/Elasticsearch-9.2.4-yellow?style=for-the-badge&logo=elasticsearch" alt="Elasticsearch">
  <img src="https://img.shields.io/badge/Docker-Ready-blue?style=for-the-badge&logo=docker" alt="Docker">
  <img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" alt="License">
</p>

<h1 align="center">ğŸ” DocuLens AI</h1>

<p align="center">
  <strong>High-accuracy document AI parser with OCR, table extraction, and 22+ Indian language support</strong>
</p>

<p align="center">
  <a href="#-features">Features</a> â€¢
  <a href="#-quick-start">Quick Start</a> â€¢
  <a href="#-api-reference">API</a> â€¢
  <a href="#-configuration">Configuration</a> â€¢
  <a href="#-architecture">Architecture</a>
</p>

---

## âœ¨ Features

### ğŸ”¤ Multi-Language OCR (22+ Indian Languages)

Powered by **PaddleOCR** with state-of-the-art accuracy:

| Status | Languages |
|--------|-----------|
| **Full Support** | English, Hindi, Bengali, Telugu, Marathi, Tamil, Gujarati, Kannada, Malayalam, Punjabi, Urdu, Nepali |
| **Fallback Support** | Odia, Assamese, Sanskrit, Konkani, Maithili, Dogri, Sindhi, Kashmiri, Manipuri, Bodo |

**Automatic script detection** for Devanagari, Bengali, Tamil, Telugu, Kannada, Malayalam, Gujarati, Gurmukhi, and Arabic scripts.

---

### ğŸ“Š Intelligent Table Extraction

Uses **Camelot** for 99%+ accuracy on PDF tables:

- **Lattice mode**: Tables with visible borders/lines
- **Stream mode**: Whitespace-separated tables
- Outputs as JSON or structured dictionaries
- Confidence scoring per table

---

### ğŸ”— Smart Chunking with Bidirectional Linkage

Every chunk maintains context awareness for RAG applications:

```json
{
  "chunk_id": "chunk_abc123",
  "prev_chunk_id": "chunk_xyz789",
  "next_chunk_id": "chunk_def456",
  "parent_section": "Chapter 1: Introduction",
  "section_hierarchy": ["Document", "Chapter 1", "Section 1.1"],
  "sibling_chunks": ["chunk_111", "chunk_222"],
  "is_continuation": true,
  "continues_to_next": true
}
```

**Three chunking strategies:**
- **Semantic**: By paragraphs and sections
- **Fixed-size**: With configurable overlap (default 10%)
- **Layout-aware**: Respects headers, tables, figures

---

### ğŸ”‘ Key-Value Pair Extraction

Extracts structured data with patterns in **22+ languages**:

| Category | Fields |
|----------|--------|
| **Common** | Name, Date, Address, Phone, Email, Amount, Age, Gender |
| **Legal (India)** | Case Number, Court, Judge, Petitioner, Respondent, FIR, Section, Police Station, District, State |
| **Hindi Examples** | à¤¨à¤¾à¤®, à¤ªà¤¤à¤¾, à¤¤à¤¾à¤°à¥€à¤–, à¤¨à¥à¤¯à¤¾à¤¯à¤¾à¤²à¤¯, à¤¯à¤¾à¤šà¤¿à¤•à¤¾à¤•à¤°à¥à¤¤à¤¾ |
| **Bengali Examples** | à¦¨à¦¾à¦®, à¦ à¦¿à¦•à¦¾à¦¨à¦¾, à¦¤à¦¾à¦°à¦¿à¦–, à¦†à¦¦à¦¾à¦²à¦¤ |

---

### ğŸ“ Embedded PDF Data Extraction

Extracts hidden metadata and embedded content:

| Data Type | Description |
|-----------|-------------|
| **Hyperlinks** | URLs, mailto:, tel: links with anchor text |
| **Email Addresses** | From links AND text (regex-based) |
| **Phone Numbers** | Indian format (+91) and international |
| **Annotations** | Comments, highlights, notes with author info |
| **Table of Contents** | PDF bookmark structure |
| **Form Fields** | Interactive PDF form values |
| **PDF Metadata** | Title, Author, Creator, Keywords |

---

### ğŸ” Elasticsearch-Powered Search

Full-text search with:
- Fuzzy matching for typos
- Highlighting of matched terms
- Faceted filtering (language, document type, state)
- Chunk-level search with context retrieval

---

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- 4GB+ RAM (8GB recommended for large documents)
- (Optional) NVIDIA GPU for faster OCR

### 1. Clone the Repository

```bash
git clone https://github.com/ShreyashDarade/Doculens-AI.git
cd Doculens-AI
```

### 2. Configure Environment

```bash
cp .env.example .env
# Edit .env to customize settings
```

### 3. Start Services

```bash
docker-compose up -d
```

Wait for Elasticsearch to be ready:

```bash
# Check health
curl http://localhost:9200/_cluster/health?pretty

# Check API
curl http://localhost:8000/api/v1/health
```

### 4. Upload Your First Document

```bash
curl -X POST "http://localhost:8000/api/v1/documents/upload" \
  -F "file=@your_document.pdf" \
  -F "language=en"
```

### 5. Access the API

- **API Docs**: http://localhost:8000/docs
- **Elasticsearch**: http://localhost:9200

---

## ğŸ“– API Reference

### Document Upload

```bash
POST /api/v1/documents/upload
```

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `file` | File | Required | PDF or image file |
| `language` | string | `en` | OCR language code |
| `chunking_strategy` | string | `semantic` | `semantic`, `fixed`, `layout` |

**Response:**
```json
{
  "document_id": "doc_abc123",
  "filename": "contract.pdf",
  "status": "processed",
  "page_count": 15,
  "chunk_count": 42,
  "processing_time_ms": 3500,
  "key_value_pairs_count": 18,
  "tables_count": 3,
  "links_count": 12,
  "emails_count": 5
}
```

---

### Get Document Chunks

```bash
GET /api/v1/documents/{document_id}/chunks?page=1&size=50
```

Returns chunks with full linkage for context-aware retrieval.

---

### Get Key-Value Pairs

```bash
GET /api/v1/documents/{document_id}/key-values
```

Returns all extracted structured data.

---

### Get Embedded Data

```bash
GET /api/v1/documents/{document_id}/embedded
```

Returns hyperlinks, emails, phone numbers, annotations, TOC, and form fields.

---

### Full-Text Search

```bash
POST /api/v1/search
Content-Type: application/json

{
  "query": "petitioner appeal",
  "page": 1,
  "size": 10,
  "filters": {
    "language_detected": "hi"
  }
}
```

---

### Get Chunk with Context

```bash
GET /api/v1/documents/{document_id}/chunk/{chunk_id}/context?window=2
```

Returns the target chunk plus surrounding chunks for RAG context.

---

## âš™ï¸ Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `ELASTICSEARCH_URL` | `http://localhost:9200` | Elasticsearch endpoint |
| `ELASTICSEARCH_INDEX` | `documents` | Index name |
| `OCR_LANGUAGE` | `en` | Primary OCR language |
| `CHUNK_SIZE` | `512` | Max tokens per chunk |
| `CHUNK_OVERLAP` | `0.1` | Overlap ratio (10%) |
| `USE_GPU` | `false` | Enable GPU acceleration |
| `MAX_FILE_SIZE_MB` | `50` | Max upload size |

### Supported Language Codes

```
en, hi, bn, te, mr, ta, gu, kn, ml, pa, ur, ne,
or, as, sa, kok, mai, doi, sd, ks, mni, sat, brx
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Document Upload                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PDF/Image Preprocessing                       â”‚
â”‚                        (PyMuPDF)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OCR   â”‚           â”‚   Layout    â”‚         â”‚  Embedded â”‚
â”‚PaddleOCRâ”‚           â”‚  Detection  â”‚         â”‚   Data    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                       â”‚                      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Table  â”‚           â”‚   Smart     â”‚         â”‚ Key-Value â”‚
â”‚Camelot  â”‚           â”‚  Chunking   â”‚         â”‚ Extractionâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                       â”‚                      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Elasticsearch Storage                       â”‚
â”‚                    (Rich Metadata + Chunks)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
doculens-ai/
â”œâ”€â”€ docker-compose.yml      # Elasticsearch + FastAPI
â”œâ”€â”€ Dockerfile             # Python 3.10 + dependencies
â”œâ”€â”€ requirements.txt       # Python packages
â”œâ”€â”€ .env.example          # Configuration template
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py           # FastAPI application
â”‚   â”œâ”€â”€ config.py         # Settings management
â”‚   â”œâ”€â”€ models/           # Pydantic models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ ocr_service.py         # PaddleOCR integration
â”‚   â”‚   â”œâ”€â”€ layout_service.py      # Layout detection
â”‚   â”‚   â”œâ”€â”€ table_service.py       # Camelot tables
â”‚   â”‚   â”œâ”€â”€ chunking_service.py    # Smart chunking
â”‚   â”‚   â”œâ”€â”€ kv_extraction.py       # Key-value extraction
â”‚   â”‚   â”œâ”€â”€ metadata_service.py    # Embedded data extraction
â”‚   â”‚   â””â”€â”€ elasticsearch_service.py
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ document_pipeline.py   # Main orchestrator
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ routes.py             # REST endpoints
â””â”€â”€ postman/
    â””â”€â”€ DocuLens_AI.postman_collection.json
```

---

## ğŸ§ª Testing

Import the Postman collection for ready-to-use API requests:

```bash
postman/DocuLens_AI.postman_collection.json
```

---

## ğŸ”§ Development

### Local Setup (Without Docker)

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows

# Install dependencies
pip install -r requirements.txt

# Start Elasticsearch separately
docker run -d -p 9200:9200 -e "discovery.type=single-node" elasticsearch:9.2.4

# Run the API
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) - Multi-language OCR
- [Camelot](https://github.com/camelot-dev/camelot) - Table extraction
- [PyMuPDF](https://github.com/pymupdf/PyMuPDF) - PDF processing
- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python API framework
- [Elasticsearch](https://www.elastic.co/) - Search and storage

---

<p align="center">
  Made with â¤ï¸ for Indian Document Processing
</p>
